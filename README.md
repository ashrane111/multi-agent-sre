# ğŸ¤– Multi-Agent SRE Platform

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![LangGraph](https://img.shields.io/badge/LangGraph-Powered-orange.svg)](https://github.com/langchain-ai/langgraph)

> **Autonomous incident response system using multi-agent AI with human-in-the-loop governance**

An intelligent SRE platform that detects, diagnoses, and remediates infrastructure incidents autonomously. Built with LangGraph for orchestration, featuring production-grade reliability patterns, RAG-powered runbook retrieval, and comprehensive audit trails.

## âœ¨ Highlights

- **~$0.002 per incident** with intelligent LLM routing (Groq â†’ Gemini â†’ Ollama fallback)
- **15-20 second resolution** for typical incidents
- **85%+ diagnosis confidence** using hybrid RAG with cross-encoder reranking
- **Full audit trail** for compliance and accountability
- **Human approval gates** for high-risk remediations

## ğŸ¯ Features

### Core Capabilities
- **5 Specialized AI Agents** coordinated via LangGraph state machine
- **Intelligent LLM Gateway** with circuit breakers and automatic failover
- **Hybrid RAG Pipeline** combining BM25 + semantic search + cross-encoder reranking
- **Episodic Memory** for learning from past incidents
- **Policy Engine** with blast radius analysis and immutable safety rules
- **Human-in-the-Loop** approval workflows with Slack notifications
- **Comprehensive Audit Trail** for all actions and decisions

### Production Reliability
- Circuit breakers with configurable thresholds
- Exponential backoff retry policies with jitter
- LLM provider fallback chain (Groq â†’ Gemini â†’ Ollama)
- Workflow checkpointing for failure recovery
- Automatic rollback on remediation failures

## ğŸ—ï¸ Architecture
<p align="center">
  <img src="assets/images/Project_architecture.png" alt="Architecture Overview" width="80%"/>
</p>

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- [Ollama](https://ollama.com) (for local LLM fallback)
- Groq API key (free tier available at [console.groq.com](https://console.groq.com))

### Installation

```bash
# Clone the repository
git clone https://github.com/ashrane111/multi-agent-sre.git
cd multi-agent-sre

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Setup environment
cp .env.example .env
# Edit .env and add your GROQ_API_KEY

# (Optional) Pull Ollama models for local fallback
ollama pull llama3.1:8b
```

### Run Demo

```bash
# Index runbook documentation
sre-platform index-runbooks

# Simulate an incident
python scripts/simulate_incident.py

# View audit trail
sre-platform audit-log

# Start API server (optional)
sre-platform serve
```

## ğŸ“ Project Structure

```
multi-agent-sre/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/          # 5 specialized AI agents
â”‚   â”‚   â”œâ”€â”€ monitor_agent.py
â”‚   â”‚   â”œâ”€â”€ diagnose_agent.py
â”‚   â”‚   â”œâ”€â”€ policy_agent.py
â”‚   â”‚   â”œâ”€â”€ remediate_agent.py
â”‚   â”‚   â””â”€â”€ report_agent.py
â”‚   â”œâ”€â”€ workflows/       # LangGraph state machine
â”‚   â”œâ”€â”€ models/          # LLM Gateway with fallback
â”‚   â”œâ”€â”€ rag/             # Hybrid RAG pipeline
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py
â”‚   â”‚   â”œâ”€â”€ reranker.py
â”‚   â”‚   â””â”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ memory/          # Episodic memory (Mem0)
â”‚   â”œâ”€â”€ hitl/            # Human-in-the-loop
â”‚   â”‚   â”œâ”€â”€ approval_manager.py
â”‚   â”‚   â””â”€â”€ slack_notifier.py
â”‚   â”œâ”€â”€ governance/      # Audit trail & policies
â”‚   â”œâ”€â”€ reliability/     # Circuit breakers, retries
â”‚   â”œâ”€â”€ mcp/             # MCP server stubs
â”‚   â””â”€â”€ api/             # FastAPI endpoints
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ runbooks/        # Incident runbooks (indexed by RAG)
â”‚   â”œâ”€â”€ policies/        # Immutable safety rules
â”‚   â””â”€â”€ audit/           # Audit log storage
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ simulate_incident.py
â”‚   â”œâ”€â”€ test_phase3.py
â”‚   â””â”€â”€ test_phase4.py
â””â”€â”€ tests/
```

## ğŸ¤– Agent Workflow

```
Alert Triggered
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MONITOR   â”‚ â”€â”€â”€ Classifies alert, extracts anomalies
â”‚    Agent    â”‚     Escalates severity if needed
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DIAGNOSE   â”‚ â”€â”€â”€ Queries RAG for runbooks
â”‚    Agent    â”‚     Recalls similar past incidents
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     Generates root cause + actions
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POLICY    â”‚ â”€â”€â”€ Checks against immutable rules
â”‚    Agent    â”‚     Calculates blast radius
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     Decides: APPROVED / NEEDS_REVIEW / BLOCKED
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HITL     â”‚ â”€â”€â”€ Creates approval request
â”‚   Gateway   â”‚     Sends Slack notification
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     Waits for human (or auto-approves P3/P4)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REMEDIATE   â”‚ â”€â”€â”€ Executes approved actions
â”‚    Agent    â”‚     Monitors for failures
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     Triggers rollback if needed
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REPORT    â”‚ â”€â”€â”€ Generates incident summary
â”‚    Agent    â”‚     Stores in episodic memory
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     Sends final notification
```

## ğŸ“Š CLI Commands

```bash
# Incident simulation
python scripts/simulate_incident.py    # Run full workflow demo

# RAG Pipeline
sre-platform index-runbooks            # Index runbook documents
sre-platform rag-search "high cpu"     # Search runbooks
sre-platform rag-stats                 # View RAG statistics

# Memory
sre-platform memory-stats              # View memory statistics
sre-platform memory-clear --confirm    # Clear episodic memory

# HITL & Governance
sre-platform approvals-pending         # List pending approvals
sre-platform approve <request_id>      # Approve a request
sre-platform reject <request_id>       # Reject a request
sre-platform audit-log                 # View audit trail
sre-platform audit-stats               # Audit statistics

# API Server
sre-platform serve                     # Start FastAPI server
sre-platform check-llm                 # Verify LLM connectivity
sre-platform cost-report               # View LLM costs
```

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/health/ready` | GET | Readiness probe |
| `/health/circuits` | GET | Circuit breaker status |
| `/api/v1/approvals/pending` | GET | List pending approvals |
| `/api/v1/approvals/{id}` | GET | Get approval details |
| `/api/v1/approvals/{id}/approve` | POST | Approve request |
| `/api/v1/approvals/{id}/reject` | POST | Reject request |
| `/api/v1/audit/entries` | GET | Query audit trail |
| `/api/v1/audit/stats` | GET | Audit statistics |
| `/api/v1/costs` | GET | LLM cost report |

## ğŸ’° Cost Analysis

| Component | Model | Cost per Call |
|-----------|-------|---------------|
| Classification | Groq llama-3.3-70b | ~$0.0004 |
| Diagnosis | Groq llama-3.3-70b | ~$0.0008 |
| Policy Check | Groq llama-3.3-70b | ~$0.0003 |
| Report Gen | Groq llama-3.3-70b | ~$0.0008 |
| Embeddings | Local (MiniLM) | FREE |
| Reranking | Local (ms-marco) | FREE |

**Total per incident: ~$0.002** (with Groq free tier: 14,400 requests/day)

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Avg Resolution Time | 15-20 seconds |
| Diagnosis Confidence | 85%+ |
| RAG Retrieval Latency | <500ms |
| LLM Fallback Success | 99.9% |
| Cost per Incident | ~$0.002 |

## ğŸ—ºï¸ Roadmap

- [x] **Phase 1-2**: Core Infrastructure + Agent Implementation
- [x] **Phase 3**: Advanced RAG + Episodic Memory
- [x] **Phase 4**: HITL & Governance
- [ ] **Phase 5**: Reliability Hardening (Chaos Testing)
- [ ] **Phase 6**: Security Layer (PII Redaction)
- [ ] **Phase 7**: Enhanced Observability (LangSmith, OpenTelemetry)
- [ ] **Phase 8**: Production Deployment Guide

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|--------------|
| Orchestration | LangGraph, Python asyncio |
| LLM Providers | Groq, Google Gemini, Ollama |
| LLM Gateway | LiteLLM |
| Vector Store | ChromaDB |
| Embeddings | sentence-transformers (MiniLM) |
| Reranking | Cross-encoder (ms-marco) |
| Memory | Mem0 (with local fallback) |
| API | FastAPI, Pydantic |
| CLI | Typer, Rich |

## ğŸ§ª Testing

```bash
# Run Phase 3 tests (RAG + Memory)
python scripts/test_phase3.py

# Run Phase 4 tests (HITL + Governance)
python scripts/test_phase4.py

# Run unit tests
pytest tests/
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ‘¤ Author

**Ashutosh Rane**
- LinkedIn: [linkedin.com/in/rane-ashutosh](https://linkedin.com/in/rane-ashutosh)
- GitHub: [@ashrane111](https://github.com/ashrane111)

---

Built with LangGraph, Groq, and multi-agent AI
